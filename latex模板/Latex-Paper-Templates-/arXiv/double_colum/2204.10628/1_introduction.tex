\section{Introduction}

Surfacing knowledge from large corpora is a crucial step when dealing with knowledge intensive language tasks~\cite{levy2017zero,dinan2018wizard,elsahar2019t,petroni-etal-2021-kilt}, such as open-domain question answering~\cite{voorhees1999trec,joshi2017triviaqa,yang2018hotpotqa,kwiatkowski-etal-2019-natural} and fact checking~\cite{Thorne18Fever}. 
A  popular paradigm to approach such tasks is to combine a search engine with a machine reader component. The former retrieves relevant context, usually in the form of short passages, which the latter then examines to produce answers~\cite{DBLP:journals/corr/ChenFWB17,lewis2020retrievalaugmented, izacard-grave-2021-leveraging}. 

In recent years we have witnessed a surge of research and development in autoregressive language models~\cite{radford2019language, Lewis2019BARTDS, 2019t5, brown2020language, rae2021scaling, artetxe2021efficient, smith2022using}, with ever increasing size and natural language understanding (NLU) capabilities. Such models are currently the de-facto implementation of the machine reader component in retrieval-reader architectures, and have contributed to rapid progress on a wide range of benchmarks \cite{joshi2017triviaqa,kwiatkowski-etal-2019-natural, petroni-etal-2021-kilt}. 
However, these tremendous advances in aggressive modelling has yet to bring similar transformational changes in  how retrieval is approached.

Transferring the NLU capabilities of modern autoregressive models to retrieval  is non-trivial. 
Some works have demonstrated that knowledge stored in the parameters of these models can be retrieved to some extend by directly generating evidence given a query \cite{petroni2019language, petroni2020context, roberts2020much}.
However, such approaches have been shown to be unreliable because of their tendency to hallucinate non-factual content \cite{massarelli2019decoding, Metzler:Rethinking21, Ji2022SurveyOH}.
To alleviate this issue, previous work proposes to only use generation for query expansion in traditional search engines \citep{mao-etal-2021-generation}, but these solutions don't exploit the full potential of autoregressive architecture, such as word order sensitivity and conditional probability modeling, and still lag behind vector-based approaches~\cite{karpukhin-etal-2020-dense}.

Recently, another line of work has investigated using autoregressive language models to generate identifier strings for documents, as an intermediate target for retrieval, such as Wikipedia page titles \citep{decao-etal-2021-autoregressive}, or root-to-leaf paths in a hierarchical cluster tree \citep{tay-etal-2022-transformer}. 
Employing identifiers, rather than generating evidence directly, induces some structure in the search space, (\ie, index documents by their title or their cluster tree) which can be easier to memorize, learn, and retrieve from, than full unstructured passages.
Moreover, it is relatively easy to constrain beam search decoding with a prefix tree ``index'' so that only valid identifiers are generated. As a downside, if appropriate metadata (e.g. titles) are not available, one needs to create the identifiers, hence the structure (e.g. with hierarchical clustering), which has not been thoroughly evaluated on a large-scale benchmark.


In this work, we propose a solution that does not force any structure in the search space, but rather uses all the ngrams occurring in a document as its identifiers.
Concretely, we introduce \textbf{S}earch \textbf{E}ngines with \textbf{A}utoregressive \textbf{L}Ms (\system{}), a retrieval solution that combines an autoregressive model, \ie, BART \citep{Lewis2019BARTDS}, with a compressed full-text substring index, \ie, the FM-Index \citep{ferragina-manzini-2000-opportunistic} --- see Figure \ref{fig:main} for an high-level overview. 
This configuration comes with a twofold benefit: i) we can constrain BART's generations with the FM-Index, hence preventing the generation of invalid identifiers (\ie, ngrams not occurring in any document); ii) the FM-Index provides information on all documents in the corpus containing a specific ngram (for every decoding step), thus allowing to retrieve them.
This setup allows \system{} to generate \emph{any span} from \emph{any position} in the corpus, without needing to explicitly encode all substrings in a document.
Moreover, we design a novel scoring function to intersect the results of multiple ngrams combining LM probabilities with FM-index frequencies (\ie, number of occurrences of the ngram in the whole corpus).%

Our experimental evaluation shows that \system{} matches or outperforms recent retrieval solutions (including autoregressive ones) on Natural Questions \cite{kwiatkowski-etal-2019-natural}, while requiring substantially less memory ($\sim$2 to 7 times smaller in footprint). Moreover, \system{}'s intersection formulation improves the state-of-the-art on passage-level retrieval by more than 10 points on the KILT benchmark \cite{petroni-etal-2021-kilt}, contributing in establishing new state-of-the-art downstream results on multiple datasets when paired with existing reader technologies. 
