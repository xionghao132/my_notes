# Accelerator

## æ¦‚è¿°

ç°åœ¨å¾ˆå¤šä»£ç ä¸­ä½¿ç”¨çš„éƒ½æ˜¯åˆ†å¸ƒå¼å¹¶è¡Œè®¡ç®—ï¼Œéœ€è¦å®šä¹‰ä¸€ç³»åˆ—çš„å‚æ•°ï¼Œæ˜¾å¾—éå¸¸å¤æ‚ã€‚è€ŒHuggingFaceçš„Accelerateå°±èƒ½å¾ˆå¥½çš„è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œåªéœ€è¦åœ¨å¹³æ—¶ç”¨çš„DataParallelç‰ˆä»£ç ä¸­ä¿®æ”¹å‡ è¡Œï¼Œå°±èƒ½å®ç°å¤šæœºå¤šå¡ã€å•æœºå¤šå¡çš„åˆ†å¸ƒå¼å¹¶è¡Œè®¡ç®—ï¼Œå¦å¤–è¿˜æ”¯æŒFP16åŠç²¾åº¦è®¡ç®—ã€‚



## ä¾‹å­

```diff
  import torch
  import torch.nn.functional as F
  from datasets import load_dataset
+ from accelerate import Accelerator

- device = 'cpu'
+ accelerator = Accelerator()

- model = torch.nn.Transformer().to(device)
+ model = torch.nn.Transformer()
  optimizer = torch.optim.Adam(model.parameters())

  dataset = load_dataset('my_dataset')
  data = torch.utils.data.DataLoader(dataset, shuffle=True)

+ model, optimizer, data = accelerator.prepare(model, optimizer, data)

  model.train()
  for epoch in range(10):
      for source, targets in data:
-         source = source.to(device)
-         targets = targets.to(device)

          optimizer.zero_grad()

          output = model(source)
          loss = F.cross_entropy(output, targets)

-         loss.backward()
+         accelerator.backward(loss)

          optimizer.step()
```



ç§»é™¤ä»£ç ä¸­æ‰€æœ‰çš„**to(device)**æˆ–è€…**cuda()**,acceleratorä¼šè‡ªåŠ¨å¸®ä½ å¤„ç†ã€‚å¦‚æœä½ çŸ¥é“è‡ªå·±çš„æƒ³æ³•ï¼Œä¹Ÿå¯ä»¥è°ƒç”¨**to(accelerator.device)**

å’Œè®­ç»ƒç›¸å…³çš„å¯¹è±¡éƒ½è¦ä¼ é€’åˆ°**prepare**æ–¹æ³•ä¸­(å¦‚æœè¦åˆ†å¸ƒå¼éªŒè¯çš„è¯ï¼Œval_dataloaderä¹Ÿéœ€è¦)



## éƒ¨ç½²åˆ†å¸ƒå¼è„šæœ¬

åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œæˆ‘ä»¬è¿˜éœ€è¦é…ç½®ä¸‹accelerateçš„è„šæœ¬ã€‚å½“ç„¶æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨**torch.distributed.launch**ï¼Œä½†æ˜¯è¦åŠ ä¸Š**--use_env**



ä½¿ç”¨è„šæœ¬çš„è¯

```sh
accelerate config
```



ä¼šæ ¹æ®ä½ å›ç­”çš„é—®é¢˜ç”Ÿæˆä¸€ä¸ªyamlæ–‡ä»¶ï¼Œæˆ‘çš„ä½äº~/.cache/huggingface/accelerate

HF_HOMEæ˜¯hugging faceçš„è·¯å¾„

ç„¶åè¿è¡Œ

```text
accelerate test
accelerate test --config_file path_to_config.yaml
```



æ£€æŸ¥é…ç½®é¡¹

```
accelerate env
```



æ¥æµ‹è¯•è„šæœ¬èƒ½å¦æ­£å¸¸å·¥ä½œã€‚ä¸€åˆ‡éƒ½okåï¼Œæˆ‘ä»¬å°±èƒ½å¼€å§‹è®­ç»ƒäº†ï¼š

```text
accelerate launch path_to_script.py --args_for_the_script
accelerate launch --config_file path_to_config.yaml path_to_script.py --args_for_the_script
```

**ä¿å­˜æ¨¡å‹ï¼š**

```python
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
accelerator.save(unwrapped_model.state_dict(), path)
```

**åŠ è½½æ¨¡å‹**ï¼š(utils.pyä¸­)

```python
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.load_state_dict(torch.load(path))

```

è¦ç”¨tqdmçš„è¯éœ€è¦ï¼š

```python
from tqdm.auto import tqdm
for epoch in tqdm(range(args.epochs), disable=not accelerator.is_local_main_
```



### gradient accumulation

```python
accelerator = Accelerator(gradient_accumulation_steps=2)
model, optimizer, training_dataloader = accelerator.prepare(model, optimizer, training_dataloader)

for input, label in training_dataloader:
    with accelerator.accumulate(model):
        predictions = model(input)
        loss = loss_function(predictions, label)
        accelerator.backward(loss)
        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()
```



## åŠ è½½å¤§æ¨¡å‹



```python
model_critic=model_critic.to('cpu')
torch.save(model_critic.state_dict(), 'model/critic')

from accelerate import init_empty_weights,load_checkpoint_and_dispatch
with init_empty_weights():
    model_reward=CriticModel()
    model_reward = load_checkpoint_and_dispatch(
    model_reward, checkpoint='model/critic', device_map="auto")
```



[huggingface/accelerate: ğŸš€ A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-precision (github.com)](https://github.com/huggingface/accelerate)

[Quick tour (huggingface.co)](https://huggingface.co/docs/accelerate/quicktour)