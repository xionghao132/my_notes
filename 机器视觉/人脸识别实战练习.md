# 实战练习

## 人脸识别

###  	捕捉人脸

 	Opencv自带训练好的人脸检测模型，存储在sources/data/haarcascades文件夹和sources/data/lbpcascades文件夹下。其中几个.xml文件如下：

* 人脸检测器（默认）：haarcascade_frontalface_default.xml
* 人脸检测器（快速Harr）：haarcascade_frontalface_alt2.xml
* 人脸检测器（侧视）：haarcascade_profileface.xml
* 眼部检测器（左眼）：haarcascade_lefteye_2splits.xml
* 眼部检测器（右眼）：haarcascade_righteye_2splits.xml
* 嘴部检测器：haarcascade_mcs_mouth.xml
* 鼻子检测器：haarcascade_mcs_nose.xml
* 身体检测器：haarcascade_fullbody.xml
* 人脸检测器（快速LBP）：lbpcascade_frontalface.xml

```python
import cv2
def face_detect_demo(img):
    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    face_detect=cv2.CascadeClassifier('haarcascade_frontalface_alt.xml') #级联分类器
    face = face_detect.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30),flags=cv2.CASCADE_SCALE_IMAGE)
    for x,y,w,h in face:
        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)
    cv2.imshow('face',img)


cap=cv2.VideoCapture(1)     #0代表电脑内置摄像头，1代表电脑外置摄像头

# img=cv2.imread('x.jpg')
# face_detect_demo(img)
while True:
    flag,frame=cap.read()
    if not flag:
        break
    face_detect_demo(frame)
    if cv2.waitKey(1)==27:
        break
cv2.destroyAllWindows()
cap.release()
```

### 人脸保存

```python
import cv2

cap=cv2.VideoCapture(0)
num=1
while(cap.isOpened()):
    ret_flag,frame=cap.read()
    cv2.imshow('face',frame)
    k=cv2.waitKey(1)
    if k==ord('s'):
        cv2.imwrite('E:/face/'+str(num)+'.jpg',frame)
        print('success save'+str(num)+'.jpg')
        print('--------------------------')
        num+=1
    elif k==ord(' '):
        break

cap.release()
cv2.destroyWindow()
```

### 数据训练

```python
import cv2
import os
from PIL import Image
import numpy as np
def getImageAndLabels(path):
    facesSamples=[]
    ids=[]
    imagePaths=[os.path.join(path,f) for f in os.listdir(path)]
    print(imagePaths)
    # 检测人脸
    face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

    # 遍历列表中的图片
    for imagePath in imagePaths:
        # 打开图片
        PIL_img = Image.open(imagePath).convert('L')
        # 将图像转换为数组
        img_numpy = np.array(PIL_img,'uint8')
        faces = face_detector.detectMultiScale(img_numpy)
        # 获取每张图片的id
        print(os.path.split(imagePath))
        id = int(os.path.split(imagePath)[1].split('.')[0])
        for x,y,w,h in faces:
            facesSamples.append(img_numpy[y:y+h,x:x+w])
            ids.append(id)
    return facesSamples,ids


if __name__== '__main__':
    #图片路径
    path = './data/jm/'
    #获取图像 数组和id标签
    faces,ids=getImageAndLabels(path)
    #获取循环对象
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.train(faces,np.array(ids))
    #保存文件
    recognizer.write('trainer/trainer.yml')

```

### 使用训练集识别人脸

```python
import cv2
from PIL import Image, ImageDraw, ImageFont
import numpy as np

#opencv写图像上文字解决乱码问题
def cv2ImgAddText(img, text, left, top, textColor=(0, 255, 0), textSize=20):
    if (isinstance(img, np.ndarray)):  # 判断是否OpenCV图片类型
        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    # 创建一个可以在给定图像上绘图的对象
    draw = ImageDraw.Draw(img)
    # 字体的格式
    fontStyle = ImageFont.truetype(
        "font/simsun.ttc", textSize, encoding="utf-8")
    # 绘制文本
    draw.text((left, top), text, textColor, font=fontStyle)

    # 转换回OpenCV格式
    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)

#加载训练数据文件
recognizer = cv2.face.LBPHFaceRecognizer_create()
recognizer.read('trainer/trainer.yml')
font = cv2.FONT_HERSHEY_SIMPLEX    #字体

#识别图片
img = cv2.imread('1.jpg')
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
face_detector = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')
faces = face_detector.detectMultiScale(gray)
for x,y,w,h in faces:
    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
    #人脸识别
    id,confidence = recognizer.predict(gray[y:y+h,x:x+w])
    print(x)
    print(y)
    img=cv2ImgAddText(img, '标签'+str(id), x + 5, y - 5,  (0, 255, 255), 20)
    img=cv2ImgAddText(img, '置信评分'+str(round(confidence,2)), x + 5, y + h - 5, (255, 255, 35), 20)
    print('id标签:',id,'置信评分',confidence)
cv2.imshow('result',img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

## 二维码识别

```python
import cv2
import numpy as np
from pyzbar.pyzbar import decode

# img = cv2.imread('./img/q3.jpg')
# code = decode(img)
cap=cv2.VideoCapture(1)
mycolor=(0,0,255)
while True:
    flag,img=cap.read()
    code=decode(img)
    for barcode in code:
        myData = barcode.data.decode('utf-8')
        pts = np.array([barcode.polygon], np.int32)
        print(pts)
        pts.reshape((-1, 1, 2))  # 负数表示任意数，系统自己整除固定后面两个数
        cv2.polylines(img, [pts], True, mycolor, 5)
        pst2 = barcode.rect
        cv2.putText(img, myData, (pst2[0], pst2[1] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, mycolor, 2)
        print(pst2)
        print(myData)
    cv2.imshow('res', img)
    if cv2.waitKey(1)==ord('q'):
        break
cv2.waitKey(0)
#print(code)

```

### 目标检测

> zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。

> a.flatten()：a是个数组，a.flatten()就是把a降到一维，默认是按行的方向降 。
>

#### 目标检测1

```python
import cv2

cap=cv2.VideoCapture(1)
cap.set(3,640)  #设置宽度
cap.set(4,480)  #设置高度
img=cv2.imread('img/x.jpg')
classNames=[]
with open('data/coco.names','r') as f:
    classNames=f.read().splitlines()
    print(classNames)
configPath='data/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt' #配置文件
weightsPath='data/frozen_inference_graph.pb'  #权重

net=cv2.dnn_DetectionModel(weightsPath,configPath)
net.setInputSize(320,320)
net.setInputScale(1.0/127.5)
net.setInputMean((127.5,127.5,127.5))
net.setInputSwapRB(True)

while True:
    flag,img=cap.read()
    classIds, confs, bbox = net.detect(img, confThreshold=0.5)
    for classId,confidence,box in zip(classIds.flatten(),confs.flatten(),bbox.flatten()):
        for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), bbox):
            cv2.rectangle(img, box, color=(0, 255, 0), thickness=2)
            cv2.putText(img, classNames[classId - 1].upper(), (box[0] + 10, box[1] + 30),
                        cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(img, str(round(confidence * 100, 2)), (box[0] + 200, box[1] + 30),
                        cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
    cv2.imshow('output',img)
    if cv2.waitKey(1)==ord('q'):
        break
```

#### 目标检测2（优化）

```python
import cv2

thres=0.45
nms_threshold=0.2   #非最大限制阈值
cap=cv2.VideoCapture(0)
cap.set(3,640)  #设置宽度
cap.set(4,480)  #设置高度
#img=cv2.imread('img/x.jpg')
classNames=[]
with open('data/coco.names','r') as f:
    classNames=f.read().splitlines()
    print(classNames)
configPath='data/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'
weightsPath='data/frozen_inference_graph.pb'

net=cv2.dnn_DetectionModel(weightsPath,configPath)
net.setInputSize(320,320)
net.setInputScale(1.0/127.5)
net.setInputMean((127.5,127.5,127.5))
net.setInputSwapRB(True)

while True:
    flag,img=cap.read()
    #classIds是编号数组从1开始，confs置信度数组，bbox二维数组每一行都是一个边界
    classIds, confs, bbox = net.detect(img, confThreshold=thres)
    bbox=list(bbox)
    confs=list(confs)
    #confs=list(confs.reshape(1,-1)[0])  #转换成list 原本就是降序
    confs=list(map(float,confs))
    #indices一维数组   应该是有去重功能
    indices=cv2.dnn.NMSBoxes(bbox,confs,thres,nms_threshold)
    for i in indices:
        box=bbox[i]
        x,y,w,h=box[0],box[1],box[2],box[3]
        cv2.rectangle(img, (x,y),(x+w,y+h), color=(0, 255, 0), thickness=2)
        cv2.putText(img, classNames[classIds[i] - 1].upper(), (box[0] + 10, box[1] + 30),
                                 cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow('output',img)
        if cv2.waitKey(1)==ord('q'):
            break
```

